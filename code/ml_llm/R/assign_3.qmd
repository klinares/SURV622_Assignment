---
title: "DOGE's Downsizing, Can AI Read the Reddit Room?"
format:
  jasa-pdf:
    keep-tex: true  
    journal:
      blinded: false
  jasa-html: default
date: last-modified
author:
  - name: Kevin Linares
    affiliations:
      - name: University of Maryland
  - name: Felix Baez-Santiago
  - name: Aria Lu
  - name: Gloria Zhou
    affiliations:
      - name: University of Michigan
abstract: |
 We investigate public sentiment on Reddit regarding the Department of Government Efficiency's federal workforce reduction by classifying 400 labeled comments (28% favor, 18% neutral, 54% oppose) using supervised and unsupervised Large Language Models. Supervised models showed moderate success, particularly with "oppose" comments, but struggled with "favor" and "neutral" stances. Similarly, LLMs best identified "oppose" sentiment but exhibited low precision for "favor" and "neutral." These findings highlight the challenges of accurately gauging nuanced public opinion on government policy changes using automated methods on social media data.
  
keywords:
  - Reddit
  - Federal Government
  - DOGE
editor: 
  markdown: 
    wrap: sentence
---

```{r include=FALSE}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, comment = FALSE)

library(readxl)
library(viridis)
library(ggthemes)
library(tidytext)
library(knitr)
library(ConfusionTableR)
library(tidyverse)



# read in ML results from repo
results_folder <- "~/repos/SURV622_Assignment/outputs/ml_llm/"

ml_results <-  read.csv(str_c(
  results_folder, "results_long.csv")) |> 
  filter( data == "counts",
    set == "test",# keep only test results
    metric %in% c("precision", "recall", "f1-score"),
    class %in% c("favor", "neutral", "oppose"),
    !str_detect(model, "Bernoulli")
         ) |> 
  # remove duplicates
  distinct() |> 
  mutate(model = str_remove(model,  "^[^|]+\\."),
         model = str_remove(model, "Classifier")) |> 
  tibble() |> 
  rename(score=value)

llama_results <- read_xlsx(str_c(
  results_folder, "reddit_comments_LLM_analysis_llama.xlsx")) |> 
  mutate_at(vars(outcome, llama, deepseek), factor) 

gemma_results <- read_csv(str_c(
  results_folder, "reddit_comments_LLM_analysis_gemma.csv")) |> 
  mutate( gemma = factor(LLM_stance))

# merge results
llm_results <- llama_results |> 
  add_column(gemma_results |> select(gemma))
```

## Introduction {#sec-intro}

The newly formed Department of Government Efficiency (DOGE) has reduced the federal workforce by almost 280,000 employees, a central pledge of the current administration.
This action has generated significant apprehension among federal workers in regards to mental health and job security.
To understand the impact of DOGE's actions on federal worker perceptions of job security, we labeled 400 Reddit comments on topics related to the current reduction in *federal* workforce by DOGE as whether the author favored, opposed, or had a neutral stance.
We use these labels to build supervised learning models to predict stance.
Additionally, we employ unsupervised large language models (LLM) to detect the stance of these Reddit comments from text, to further explore appropriate models for this current topic.

## Methods {#sec-meth}

*Data*.
We collected Reddit comments from subreddits related to the topic of interest in early March of 2024.
This resulted in 12,553 comments which we preprocessed by removing web-URLs, replace special characters (i.e., replaced "\@" with "at"), replaced numeric values with their spelling, and confirmed the absence of duplicate comments.
We then randomly selected 400 comments (without replacement) and assigned them to four graduate students for coding, categorizing each comment as favoring, opposing, or neutral towards DOGE's approach to federal workforce reductions.
Table 1 presents the breakdown in percent of our the comments we labelled and later use to train and evaluate our machine learning models.
A review of the comments revealed more negative opinionated statements and reactions.

```{r}
llm_results |> 
  count(outcome) |> 
  mutate(Percent = n/sum(n),
         Percent = round(Percent* 100)) |> 
  select(outcome, Percent) |> 
  kable(caption="Distribution of labeled Reddit comment data.")
```

We built two supervised machine learning models–K-nearest neighbor and random forest–to classify Reddit comments concerning stance on the current reduction in federal workforce into favor, oppose, or neutral.
For predictors we used the Reddit score, up-votes, and down-votes each comment received at the time of the collection.
Additionally, we used the keyword that was used to scrape these data along with the subreddit where the comment was posted.
**DISCUSS ADDITIONAL FEATURE ENGINERRING SUCH AS TEXT EDITING THAT WENT INTO THE MODEL.** For the KNN model, we set the number of neighbors hyperparameter to three, and for the random forest, mtry was kept at a constant two as we did not have many features in these models.
We took an 80/20 split for our training-testing sets that we used to train each model and evaluate.

In addition to our supervised machine learning models, we also applied to our comments two LLMs, gemma 3.12 and llama 3.2.
3B.
Gemma, was developed by Google and is based on Gemini, is able to generate text output using instruction-tuned prompts from the user, such as providing answers on a user specified task reviewing text.
We deployed gemma on a higher performance computing cluster ([Great Lakes HCP](https://its.umich.edu/advanced-research-computing/)) and processed text from Reddit comments on a GPU.
We were also interested in deploying other lightweight LLMs locally on a machine with a dedicated-GPU and found llama, developed by Meta AI, to be an excellent candidate.
Llama excels at text classification which is how we used it to classify the stance for each comment text given a user specified prompt.
We choose both of these LLMs as candidates to test against our supervised approaches because of their ability to apply locally and reputable performance on zero-shot classification tasks.
Both of these models received the same prompt and tasked which were developed by the research team to reflect the utility of classifying stance within our topic of interest.

|  |  |
|----------------|--------------------------------------------------------|
| **Prompt**: | "Is this comment in 'favor', 'neutral', or 'oppose' the reduction in federal workforce? Provide one word answer only! |
| **Task**: | "You have assumed the role of a stakeholder that is presented with a reddit comment from a likely federal worker related to the current policies on reducing the federal workforce. Please determine the author's stance on this topic, and only provide the answer." |

We evaluate model performance using the F1-score which is a harmonic mean balance between precision and recall.
This metric considers both the ability to correctly identify positive instances, known as recall, and the ability to avoid incorrectly labeling negative instances as positive (i.e., precision).
A high F1-score indicates a model with well balanced recall and precision that both minimize false negativesand false positives.
The second performance metric we used is recall, as this determines how many of the actual positive cases the model can correctly identify.
Recall can be prone to incorrectly labeling negative cases as positive, suggesting more false positives, which is why we intereggoate on two performance metrics in this study.

## Results

Our machine learning models reveal a mix of performance results in classifying the stance of Reddit comment into favor, neutral, oppose.
Both models exhibit low recall and F1-scores for the "favor" stance (see Figure 1), yet the random forest model (recall .26: f1-score .28) slightly outperforms KNN (recall .16: f1-score .19).
The "neutral" class presented a significant challenge for the random forest with very low scores (recall .05: f1-score .10), while KNN exhibited slightly better performance (recall .21: f1-score .21).
Both models showed the strongest performance in identifying comments expressing opposition.
The random forest correctly identified 74 percent of all the actual Reddit comments expressing opposition compared to KNN at 64 percent, meaning that KNN missed a larger proportion of true "oppose" comments.
The f1-scores were similar for both models at 60 percent, this implies that KNN may have a slightly higher precision score given that it had a lower recall score than the random forest model.
This implies that when KNN predicts comments for the "oppose" class, it is as likely as the random forest to be correct.

```{r}
#| fig-width: 7
#| fig-height: 6
#| 
# number of total posts
ml_results |> 
  # filter models needed
  filter(model %in% 
           c("RandomForest", "KNeighbors"),
         metric %in% c("f1-score", "recall")) |> 
  ggplot(aes(x=model, y=score, fill=class)) +
  geom_col(position="dodge") +  
  coord_flip() +
  facet_grid(~metric) +
  guides(fill=guide_legend(title="", reverse = TRUE)) +
  scale_fill_viridis_d(option="F", direction = -1,
                       alpha=.85, end =.70, begin=.15) +
  labs(
    title = "Figure 1. Recall and precision scores for random forest
    and KNN models.",
    x = "Models",
    y = "Performance Scores"
  ) +
  theme_hc()

```

The LLMs, showed poor performance in classifying the "favor" stance, with very low f1-scores (llama .07: gemma .02) despite moderate recall (llama .29: gemma .33), indicating low precision (see Figure 2).
For the "neutral" class, both models showed modest results, with llama achieving a slightly better F1-score (.23) compared to gemma (0.18), although gemma had a higher recall (.50 vs .25), again suggesting lower precision for gemma.
Similar to the supervised models, both LLMs performed best in classifying the "oppose" stance, with relatively high and similar F1-scores (llama .67: gemma .70) and comparable recall (llama .56: gemma .56), suggesting a better balance between precision and recall for this category.
Both models correctly identify 67 to 70 percent of all the actual Reddit comments expressing opposition.
Overall, both LLMs struggled with the "favor" and "neutral" classes but demonstrated a stronger ability to identify opposing comments.\

```{r}

 cm_metric_fun <- function(dat, model_name){
   
   subset_dat <- dat |> 
     # truth should go first, predicted 2nd
     select(outcome, all_of(model_name)) |> 
     rename(predictor = 2)
   
  cm_ob = multi_class_cm(subset_dat$outcome, 
                        subset_dat$predictor,
                        mode="everything")
   
  result = cm_ob$record_level_cm |> 
   tibble() |> 
   select(contains(c("f1", "recall"))) |> 
   pivot_longer(everything()) |> 
   separate(name, c("class", "metric")) |> 
   mutate(model = model_name) |> 
   rename(score=value)
  
  return(result)
 }
 
 llama_metrics <- cm_metric_fun(
   dat = llm_results, 
   model_name = "llama") # name of predicted column
 
gemma_metrics <- cm_metric_fun(
   dat = llm_results, 
   model_name = "gemma" # name of predicted column
 )
 
 metric_results <- llama_metrics |> 
   add_row(gemma_metrics)
   
```

```{r}
#| fig-width: 7
#| fig-height: 6
#| 
metric_results |> 
  filter(metric %in% c("F1", "Recall")) |> 
  ggplot(aes(x=model, y=score, fill=class)) +
  geom_col(position="dodge") +  
  coord_flip() +
  facet_grid(~metric) +
  guides(fill=guide_legend(title="", reverse = TRUE)) +
  scale_fill_viridis_d(option="F", direction = -1,
                       alpha=.85, end =.70, begin=.15) +
  labs(
    title = "Figure 2. Recall and precision scores for LLMs.",
    x = "Models",
    y = "Performance Scores"
  ) +
  theme_hc()
```

Gemma and llama demonstrated only fair agreement in stance classification (Cohen's Kappa = .24).
The contingency table, Table 2 below, reveals highest agreement for "oppose" (.80), indicating some consistency in identifying a strong negative stance.
However, agreement was substantially lower for "neutral" (.03) and "favor" (.01), highlighting divergent interpretations of more nuanced language.
Off-diagonal values further illustrate these discrepancies, suggesting fundamental differences in how the models process ambiguous cues and establish classification boundaries, particularly for less extreme stances.

```{r}
cm_results <- multi_class_cm(llm_results$llama, 
                              llm_results$gemma)

coh_kappa <-  cm_results$record_level_cm |> 
  pull(contains("Kappa"))
  
cm_results$cm_tbl |> 
    kable(caption=str_c("Aggreement between LLMs, Cohens Kappa, ", 
                        round(coh_kappa, 2)))


```

## Conclusion

We explored public sentiment on Reddit regarding the DOGE federal workforce reduction using supervised learning (KNN, Random Forest) and unsupervised LLMs ( gemma 3.12b and Llama 3.2 3B) for stance classification.
Our supervised learning models achieved moderate success in this classification task, with the strongest performance in identifying opposing viewpoints, which were also the most prevalent in our labeled data.
Moreover, both models struggled with the "favor" and "neutral" stances, suggesting limitations in our initial features to capture these nuances.
Our unsupervised learning models also showed the best ability to classify "oppose" comments, yet exhibited significant challenges with the "favor" and "neutral" categories, particularly demonstrating low precision.

This study had limitations such as the small size of our labelled dataset of 400 Reddit, imbalance in the stance categories, and few features in the supervised approach.
The zero-shot capabilities of the LLMs are suitable for topic exploration but may require fine-tuning for optimal performance on this specific domain, particularly with nuance language used in "favor" comments.
Future research should continue to understand federal worker perceptions and improve stance classification by expanding labeled dataset and incorporate more contextual text rather than single comment text.
Fine tuning LLMs on a larger corpus with relevant comments could render more accuracy in the classification task.
