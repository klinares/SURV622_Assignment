{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Required Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install beautifulsoup4 lxml nltk spacy textblob emoji pandas openpyxl scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import nltk\n",
    "import numpy\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from pandas import read_excel\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Load spaCy for Lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: Hello! ðŸ˜Š This is a <b>test</b> message. Visit: https://example.com #AI @user123\n",
      "Clean: hello smilingfacewithsmilingeye test message visit\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove HTML tag\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    " \n",
    "    # Remove URL\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    " \n",
    "    # Remove @user and #tag\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
    " \n",
    "    # Replace emoji\n",
    "    text = emoji.demojize(text)\n",
    " \n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    " \n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    " \n",
    "    # Lower the text\n",
    "    text = text.lower()\n",
    " \n",
    "    # Lemmatization\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc])\n",
    " \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    " \n",
    "    # Correct\n",
    "    text = str(TextBlob(text).correct())\n",
    " \n",
    "    return text\n",
    " \n",
    "# Test\n",
    "raw_text = \"Hello! ðŸ˜Š This is a <b>test</b> message. Visit: https://example.com #AI @user123\"\n",
    "cleaned_text = clean_text(raw_text)\n",
    "print(\"Raw:\", raw_text)\n",
    "print(\"Clean:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets and Clean Fileds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_excel(\"./merged_codes.xlsx\"); dataset\n",
    "dataset[\"CleanText\"] = dataset[\"comment\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score are equal to upvotes\n",
    "numpy.sum(dataset[\"score\"] == dataset[\"upvotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"score_no_negative\"] = dataset[\"score\"] + dataset[\"score\"].min() * -1\n",
    "dataset['subreddit_label'] = LabelEncoder().fit(dataset[\"subreddit\"]).transform(dataset[\"subreddit\"])\n",
    "dataset['search_term_label'] = LabelEncoder().fit(dataset[\"search_term\"]).transform(dataset[\"search_term\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unigrams and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "count_vect = CountVectorizer(stop_words = \"english\", decode_error = \"ignore\")\n",
    "text_counts = count_vect.fit_transform(dataset[\"CleanText\"])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "text_tfidf = tfidf_transformer.fit_transform(text_counts)\n",
    "\n",
    "# Downvotes are constant\n",
    "x_counts = hstack((dataset[[\"score_no_negative\", \"subreddit_label\", \"search_term_label\"]].values, text_counts))\n",
    "x_tfidf = hstack((dataset[[\"score_no_negative\", \"subreddit_label\", \"search_term_label\"]].values, text_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_counts, x_test_counts, x_train_tfidf, x_test_tfidf, y_train, y_test = train_test_split(x_counts, x_tfidf, dataset[\"outcome\"], test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Batch Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: Transform Labels for `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_int(y):\n",
    "    if y == \"oppose\":\n",
    "        return 0\n",
    "    if y == \"favor\":\n",
    "        return 1\n",
    "    if y == \"neutral\":\n",
    "        return 2\n",
    "\n",
    "def transform_to_label(y):\n",
    "    if y == 0:\n",
    "        return \"oppose\"\n",
    "    if y == 1:\n",
    "        return \"favor\"\n",
    "    if y == 2:\n",
    "        return \"neutral\"\n",
    "\n",
    "def transform_y(y, model_tag):\n",
    "    if model_tag == \"xgboost.XGBClassifier\":\n",
    "        return y.apply(transform_to_int)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9378531073446328,\n",
       "  'recall': 0.9485714285714286,\n",
       "  'f1-score': 0.9431818181818182,\n",
       "  'support': 175},\n",
       " '1': {'precision': 0.925531914893617,\n",
       "  'recall': 0.9560439560439561,\n",
       "  'f1-score': 0.9405405405405406,\n",
       "  'support': 91},\n",
       " '2': {'precision': 0.9183673469387755,\n",
       "  'recall': 0.8333333333333334,\n",
       "  'f1-score': 0.8737864077669903,\n",
       "  'support': 54},\n",
       " 'accuracy': 0.93125,\n",
       " 'macro avg': {'precision': 0.9272507897256751,\n",
       "  'recall': 0.9126495726495727,\n",
       "  'f1-score': 0.919169588829783,\n",
       "  'support': 320},\n",
       " 'weighted avg': {'precision': 0.9310610461728868,\n",
       "  'recall': 0.93125,\n",
       "  'f1-score': 0.9307202293450777,\n",
       "  'support': 320}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(model, x, y):\n",
    "    return model.fit(x, y)\n",
    "\n",
    "def predict(fit, x):\n",
    "    return fit.predict(x)\n",
    "\n",
    "def train_and_evaluate(model, x, y):\n",
    "    fit = train(model, x, y)\n",
    "    pred = predict(fit, x)\n",
    "    gof = classification_report(y, pred, output_dict = True)\n",
    "    return fit, gof\n",
    "\n",
    "# Test\n",
    "fit, gof = train_and_evaluate(XGBClassifier(), x_train_counts, y_train.apply(transform_to_int)); gof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Test and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.5192307692307693,\n",
       "  'recall': 0.6428571428571429,\n",
       "  'f1-score': 0.574468085106383,\n",
       "  'support': 42},\n",
       " '1': {'precision': 0.2857142857142857,\n",
       "  'recall': 0.3157894736842105,\n",
       "  'f1-score': 0.3,\n",
       "  'support': 19},\n",
       " '2': {'precision': 0.42857142857142855,\n",
       "  'recall': 0.15789473684210525,\n",
       "  'f1-score': 0.23076923076923078,\n",
       "  'support': 19},\n",
       " 'accuracy': 0.45,\n",
       " 'macro avg': {'precision': 0.4111721611721612,\n",
       "  'recall': 0.37218045112781956,\n",
       "  'f1-score': 0.3684124386252046,\n",
       "  'support': 80},\n",
       " 'weighted avg': {'precision': 0.44223901098901097,\n",
       "  'recall': 0.45,\n",
       "  'f1-score': 0.4276534369885434,\n",
       "  'support': 80}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_and_evaluate(fit, x, y):\n",
    "    pred = predict(fit, x)\n",
    "    gof = classification_report(y, pred, output_dict = True)\n",
    "    return gof\n",
    "\n",
    "# Test\n",
    "gof = test_and_evaluate(fit, x_test_counts, y_test.apply(transform_to_int)); gof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: Format Good-of-fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>counts</td>\n",
       "      <td>xgboost.XGBClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>oppose</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>counts</td>\n",
       "      <td>xgboost.XGBClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>favor</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>counts</td>\n",
       "      <td>xgboost.XGBClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>counts</td>\n",
       "      <td>xgboost.XGBClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>counts</td>\n",
       "      <td>xgboost.XGBClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.411172</td>\n",
       "      <td>0.372180</td>\n",
       "      <td>0.368412</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>counts</td>\n",
       "      <td>xgboost.XGBClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.442239</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.427653</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data                  model   set         class  precision    recall  \\\n",
       "0  counts  xgboost.XGBClassifier  test        oppose   0.519231  0.642857   \n",
       "1  counts  xgboost.XGBClassifier  test         favor   0.285714  0.315789   \n",
       "2  counts  xgboost.XGBClassifier  test       neutral   0.428571  0.157895   \n",
       "3  counts  xgboost.XGBClassifier  test      accuracy        NaN       NaN   \n",
       "4  counts  xgboost.XGBClassifier  test     macro avg   0.411172  0.372180   \n",
       "5  counts  xgboost.XGBClassifier  test  weighted avg   0.442239  0.450000   \n",
       "\n",
       "   f1-score  support  accuracy  \n",
       "0  0.574468     42.0       NaN  \n",
       "1  0.300000     19.0       NaN  \n",
       "2  0.230769     19.0       NaN  \n",
       "3       NaN      NaN      0.45  \n",
       "4  0.368412     80.0       NaN  \n",
       "5  0.427653     80.0       NaN  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_gof(gof, model_tag):\n",
    "    if model_tag == \"xgboost.XGBClassifier\":\n",
    "        return {\n",
    "            transform_to_label(0): gof[\"0\"],\n",
    "            transform_to_label(1): gof[\"1\"],\n",
    "            transform_to_label(2): gof[\"2\"],\n",
    "            \"accuracy\": gof[\"accuracy\"],\n",
    "            \"macro avg\": gof[\"macro avg\"],\n",
    "            \"weighted avg\": gof[\"weighted avg\"]\n",
    "        }\n",
    "    return gof\n",
    "\n",
    "def format_gof_long(gof, model_tag, data_tag, set_tag):\n",
    "    records = []\n",
    "    for item in gof:\n",
    "        if item == \"accuracy\":\n",
    "            record = {\n",
    "                \"data\": data_tag,\n",
    "                \"model\": model_tag,\n",
    "                \"set\": set_tag,\n",
    "                \"class\": \"accuracy\",\n",
    "                \"metric\": \"accuracy\",\n",
    "                \"value\": gof[item]\n",
    "            }\n",
    "            records.append(record)\n",
    "        else:\n",
    "            record = []\n",
    "            for metric in [\"precision\", \"recall\", \"f1-score\", \"support\"]:\n",
    "                record.append({\n",
    "                    \"data\": data_tag,\n",
    "                    \"model\": model_tag,\n",
    "                    \"set\": set_tag,\n",
    "                    \"class\": item,\n",
    "                    \"metric\": metric,\n",
    "                    \"value\": gof[item][metric]\n",
    "                })\n",
    "                records.extend(record)\n",
    "    return records\n",
    "\n",
    "def format_gof_wide(gof, model_tag, data_tag, set_tag):\n",
    "    records = []\n",
    "    for item in gof:\n",
    "        if item == \"accuracy\":\n",
    "            record = {\n",
    "                \"data\": data_tag,\n",
    "                \"model\": model_tag,\n",
    "                \"set\": set_tag,\n",
    "                \"class\": \"accuracy\",\n",
    "                \"accuracy\": gof[item]\n",
    "            }\n",
    "            records.append(record)\n",
    "        else:\n",
    "            record = {\n",
    "                \"data\": data_tag,\n",
    "                \"model\": model_tag,\n",
    "                \"set\": set_tag,\n",
    "                \"class\": item\n",
    "            }\n",
    "            for metric in [\"precision\", \"recall\", \"f1-score\", \"support\"]:\n",
    "                record.update({\n",
    "                    metric: gof[item][metric]\n",
    "                })\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "# Test\n",
    "DataFrame(format_gof_wide(\n",
    "    transform_gof(gof, \"xgboost.XGBClassifier\"), \n",
    "    model_tag = \"xgboost.XGBClassifier\", \n",
    "    data_tag = \"counts\",\n",
    "    set_tag = \"test\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: Batch Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_tag):\n",
    "    if model_tag == \"sklearn.ensemble.ExtraTreesClassifier\":\n",
    "        return ExtraTreesClassifier()\n",
    "    if model_tag == \"sklearn.ensemble.RandomForestClassifier\":\n",
    "        return RandomForestClassifier()\n",
    "    if model_tag == \"sklearn.linear_model.LogisticRegression\":\n",
    "        return LogisticRegression()\n",
    "    if model_tag == \"sklearn.linear_model.RidgeClassifier\":\n",
    "        return RidgeClassifier()\n",
    "    if model_tag == \"sklearn.neighbors.KNeighborsClassifier\":\n",
    "        return KNeighborsClassifier()\n",
    "    if model_tag == \"sklearn.neighbors.NearestCentroid\":\n",
    "        return NearestCentroid()\n",
    "    if model_tag == \"sklearn.neural_network.MLPClassifier\":\n",
    "        return MLPClassifier()\n",
    "    if model_tag == \"sklearn.naive_bayes.BernoulliNB\":\n",
    "        return BernoulliNB()\n",
    "    if model_tag == \"sklearn.naive_bayes.MultinomialNB\":\n",
    "        return MultinomialNB()\n",
    "    if model_tag == \"sklearn.svm.LinearSVC\":\n",
    "        return LinearSVC()\n",
    "    if model_tag == \"sklearn.tree.DecisionTreeClassifier\":\n",
    "        return DecisionTreeClassifier()\n",
    "    if model_tag == \"sklearn.tree.ExtraTreeClassifier\":\n",
    "        return ExtraTreeClassifier()\n",
    "    if model_tag == \"xgboost.XGBClassifier\":\n",
    "        return XGBClassifier()\n",
    "\n",
    "def train_test_evaluate(model_tag, data, data_tag):\n",
    "    x_train, y_train, x_test, y_test = data\n",
    "    y_train, y_test = transform_y(y_train, model_tag), transform_y(y_test, model_tag)\n",
    "\n",
    "    model = create_model(model_tag)\n",
    "\n",
    "    fit, train_gof = train_and_evaluate(model, x_train, y_train)\n",
    "    train_gof_long = format_gof_long(train_gof, model_tag, data_tag, \"train\")\n",
    "    train_gof_wide = format_gof_wide(train_gof, model_tag, data_tag, \"train\")\n",
    "\n",
    "    test_gof = test_and_evaluate(fit, x_test, y_test)\n",
    "    test_gof_long = format_gof_long(test_gof, model_tag, data_tag, \"test\")\n",
    "    test_gof_wide = format_gof_wide(test_gof, model_tag, data_tag, \"test\")\n",
    "    \n",
    "    return fit, train_gof_long, train_gof_wide, test_gof_long, test_gof_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined All Models and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tags = [\n",
    "    \"sklearn.ensemble.ExtraTreesClassifier\",\n",
    "    \"sklearn.ensemble.RandomForestClassifier\",\n",
    "    \"sklearn.linear_model.LogisticRegression\",\n",
    "    \"sklearn.linear_model.RidgeClassifier\",\n",
    "    \"sklearn.neighbors.KNeighborsClassifier\",\n",
    "    \"sklearn.neighbors.NearestCentroid\",\n",
    "    \"sklearn.neural_network.MLPClassifier\",\n",
    "    \"sklearn.naive_bayes.BernoulliNB\",\n",
    "    \"sklearn.naive_bayes.MultinomialNB\",\n",
    "    \"sklearn.svm.LinearSVC\",\n",
    "    \"sklearn.tree.DecisionTreeClassifier\",\n",
    "    \"sklearn.tree.ExtraTreeClassifier\",\n",
    "    \"xgboost.XGBClassifier\"\n",
    "]\n",
    "\n",
    "data_tags = [\"counts\", \"tfidf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing counts using sklearn.ensemble.ExtraTreesClassifier: done.\n",
      "Processing counts using sklearn.ensemble.RandomForestClassifier: done.\n",
      "Processing counts using sklearn.linear_model.LogisticRegression: done.\n",
      "Processing counts using sklearn.linear_model.RidgeClassifier: done.\n",
      "Processing counts using sklearn.neighbors.KNeighborsClassifier: done.\n",
      "Processing counts using sklearn.neighbors.NearestCentroid: done.\n",
      "Processing counts using sklearn.neural_network.MLPClassifier: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Processing counts using sklearn.naive_bayes.BernoulliNB: done.\n",
      "Processing counts using sklearn.naive_bayes.MultinomialNB: done.\n",
      "Processing counts using sklearn.svm.LinearSVC: done.\n",
      "Processing counts using sklearn.tree.DecisionTreeClassifier: done.\n",
      "Processing counts using sklearn.tree.ExtraTreeClassifier: done.\n",
      "Processing counts using xgboost.XGBClassifier: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Processing tfidf using sklearn.ensemble.ExtraTreesClassifier: done.\n",
      "Processing tfidf using sklearn.ensemble.RandomForestClassifier: done.\n",
      "Processing tfidf using sklearn.linear_model.LogisticRegression: done.\n",
      "Processing tfidf using sklearn.linear_model.RidgeClassifier: done.\n",
      "Processing tfidf using sklearn.neighbors.KNeighborsClassifier: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Processing tfidf using sklearn.neighbors.NearestCentroid: done.\n",
      "Processing tfidf using sklearn.neural_network.MLPClassifier: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Processing tfidf using sklearn.naive_bayes.BernoulliNB: done.\n",
      "Processing tfidf using sklearn.naive_bayes.MultinomialNB: done.\n",
      "Processing tfidf using sklearn.svm.LinearSVC: done.\n",
      "Processing tfidf using sklearn.tree.DecisionTreeClassifier: done.\n",
      "Processing tfidf using sklearn.tree.ExtraTreeClassifier: done.\n",
      "Processing tfidf using xgboost.XGBClassifier: done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./Results\"):\n",
    "    os.makedirs(\"./Results\")\n",
    "\n",
    "for data_tag in data_tags:\n",
    "    if data_tag == \"counts\":\n",
    "        data = x_train_counts, y_train, x_test_counts, y_test\n",
    "    if data_tag == \"tfidf\":\n",
    "        data = x_train_tfidf, y_train, x_test_tfidf, y_test\n",
    "    for model_tag in model_tags:\n",
    "        pickle_file = f\"./Results/{data_tag}+{model_tag}.pickle\"\n",
    "        if os.path.exists(pickle_file):\n",
    "            print(f\"Skipping {data_tag} using {model_tag}: already exists.\")\n",
    "            continue\n",
    "        print(f\"Processing {data_tag} using {model_tag}: \", end = \"\")\n",
    "        result = train_test_evaluate(model_tag, data, data_tag)\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            pickle.dump(result, f)\n",
    "        print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_long, results_wide = [], []\n",
    "\n",
    "for data_tag in data_tags:\n",
    "    for model_tag in model_tags:\n",
    "        pickle_file = f\"./Results/{data_tag}+{model_tag}.pickle\"\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            fit, train_gof_long, train_gof_wide, test_gof_long, test_gof_wide = pickle.load(f)\n",
    "        results_long.extend(train_gof_long)\n",
    "        results_long.extend(test_gof_long)\n",
    "        results_wide.extend(train_gof_wide)\n",
    "        results_wide.extend(test_gof_wide)\n",
    "\n",
    "DataFrame(results_wide).to_csv(\"results_wide.csv\", index = False)\n",
    "DataFrame(results_long).to_csv(\"results_long.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
